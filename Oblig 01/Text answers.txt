### Compulsary assignment 01 ###

Name: Ole Kristian Westby.

## PART 1 ##

### TASK 1 ###



Code for the first task is included in the task1.c file.

1. Compiling it and running main gives us a Segmentation fault (core dumped). 

2. When we run it with the debugger, it also gives a segmentation fault, but also points to the line where the error occured.

(gdb) run
Starting program: /home/owe005/Documents/inf113oblig/main 

Program received signal SIGSEGV, Segmentation fault.
0x0000555555555161 in main () at task1.c:6
6	printf("Ptr: %d\n",(*ptr));

3. Lastly running it with valgrind gives us a segmentation fault, and again at line 6. 

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ valgrind ./main
==7428== Memcheck, a memory error detector
==7428== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==7428== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info
==7428== Command: ./main
==7428== 
==7428== Invalid read of size 4
==7428==    at 0x109161: main (task1.c:6)
==7428==  Address 0x0 is not stack'd, malloc'd or (recently) free'd
==7428== 
==7428== 
==7428== Process terminating with default action of signal 11 (SIGSEGV)
==7428==  Access not within mapped region at address 0x0
==7428==    at 0x109161: main (task1.c:6)
==7428==  If you believe this happened as a result of a stack
==7428==  overflow in your program's main thread (unlikely but
==7428==  possible), you can try to increase the size of the
==7428==  main thread stack using the --main-stacksize= flag.
==7428==  The main thread stack size used in this run was 8388608.
==7428== 
==7428== HEAP SUMMARY:
==7428==     in use at exit: 0 bytes in 0 blocks
==7428==   total heap usage: 0 allocs, 0 frees, 0 bytes allocated
==7428== 
==7428== All heap blocks were freed -- no leaks are possible
==7428== 
==7428== For lists of detected and suppressed errors, rerun with: -s
==7428== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0)
Segmentation fault (core dumped)
owe005@owe005-VirtualBox:~/Documents/inf113oblig$ 

It seems like the amount of information you're given about what's wrong differs from which way you try and figure out the issue. Whether that is to run the code, debug it or use valgrind. Valgrind is giving the most detailed description of the issue. The error segmentation fault usually means that a program is trying to read or write an illegal memory location.



### TASK 2 ###



Code for the second task is included in the task2.c file.

1. Compiling it and running it gives us no errors, so from just running it, it seems there is nothing wrong.

2. With the debugger it also gives us no errors.

(gdb) run
Starting program: /home/owe005/Documents/inf113oblig/main 
[Inferior 1 (process 6936) exited normally]

3. However, with Valgrind we get:

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ valgrind --leak-check=yes ./main
==7788== Memcheck, a memory error detector
==7788== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==7788== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info
==7788== Command: ./main
==7788== 
==7788== 
==7788== HEAP SUMMARY:
==7788==     in use at exit: 400 bytes in 1 blocks
==7788==   total heap usage: 1 allocs, 0 frees, 400 bytes allocated
==7788== 
==7788== 400 bytes in 1 blocks are definitely lost in loss record 1 of 1
==7788==    at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so)
==7788==    by 0x10915E: main (task2.c:7)
==7788== 
==7788== LEAK SUMMARY:
==7788==    definitely lost: 400 bytes in 1 blocks
==7788==    indirectly lost: 0 bytes in 0 blocks
==7788==      possibly lost: 0 bytes in 0 blocks
==7788==    still reachable: 0 bytes in 0 blocks
==7788==         suppressed: 0 bytes in 0 blocks
==7788== 
==7788== For lists of detected and suppressed errors, rerun with: -s
==7788== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0)


With valgrind we are able to see that there is an error.



### TASK 3 ###



Code for the third task is included in the task3.c file.

1. Again, running the program is giving no errors.

2. Same with the debugger.

Starting program: /home/owe005/Documents/inf113oblig/main 
[Inferior 1 (process 7292) exited normally]

3. With valgrind we are able to see errors.

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ valgrind --leak-check=yes ./main
==7322== Memcheck, a memory error detector
==7322== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==7322== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info
==7322== Command: ./main
==7322== 
==7322== Invalid write of size 4
==7322==    at 0x10916D: main (task3.c:5)
==7322==  Address 0x4a501d0 is 0 bytes after a block of size 400 alloc'd
==7322==    at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so)
==7322==    by 0x10915E: main (task3.c:4)
==7322== 
==7322== 
==7322== HEAP SUMMARY:
==7322==     in use at exit: 400 bytes in 1 blocks
==7322==   total heap usage: 1 allocs, 0 frees, 400 bytes allocated
==7322== 
==7322== 400 bytes in 1 blocks are definitely lost in loss record 1 of 1
==7322==    at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so)
==7322==    by 0x10915E: main (task3.c:4)
==7322== 
==7322== LEAK SUMMARY:
==7322==    definitely lost: 400 bytes in 1 blocks
==7322==    indirectly lost: 0 bytes in 0 blocks
==7322==      possibly lost: 0 bytes in 0 blocks
==7322==    still reachable: 0 bytes in 0 blocks
==7322==         suppressed: 0 bytes in 0 blocks
==7322== 
==7322== For lists of detected and suppressed errors, rerun with: -s
==7322== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0)

The problem with the code from reading the valgrind output seems to be that data[100] is not allocated.



### TASK 4 ###



Code for the fourth task is included in the task4.c file.

The program runs fine after compiling it, although it does not print anything.

However running with valgrind gives us

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ valgrind  ./main
==9540== Memcheck, a memory error detector
==9540== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==9540== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info
==9540== Command: ./main
==9540== 
==9540== Invalid read of size 4
==9540==    at 0x1091B3: main (task4.c:7)
==9540==  Address 0x4a50040 is 0 bytes inside a block of size 400 free'd
==9540==    at 0x483CA3F: free (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so)
==9540==    by 0x1091AE: main (task4.c:6)
==9540==  Block was alloc'd at
==9540==    at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so)
==9540==    by 0x10919E: main (task4.c:5)
==9540== 
==9540== 
==9540== HEAP SUMMARY:
==9540==     in use at exit: 0 bytes in 0 blocks
==9540==   total heap usage: 2 allocs, 2 frees, 1,424 bytes allocated
==9540== 
==9540== All heap blocks were freed -- no leaks are possible
==9540== 
==9540== For lists of detected and suppressed errors, rerun with: -s
==9540== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0)

Valgrind is telling us that the program will not run because we are trying to print an element of that pointer who's memory is freed.



### TASK 5 ###



Code for the fifth task is included in the task5.c file.

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main
free(): invalid pointer
Aborted (core dumped)

What happens is when we try to free a value not allocated by malloc, the program crashes because the pointer was not allocated. Essentially it's undefined behaviour.



### TASK 6 ###

I first compile the program and run it with some quick tests. 

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 1 2
3
owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 2 2
4
owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 1 1
2
owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 0 1
1
owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 1000 100000
101000

It's apparent that this program takes two integers as an input, but with floats it does not work. 

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 1.9 1.1
2

However, when you start experimenting with largerst numbers, we will see the error come up. Segmentation fault (core dumped)

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 1 261868
261869
owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 1 261869
Segmentation fault (core dumped)

When we run it with valgrind we can see that the error is stack overflow, due to increasing depth of recursion in silly_add:

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ valgrind ./main 1 999999
==12069== Memcheck, a memory error detector
==12069== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==12069== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info
==12069== Command: ./main 1 999999
==12069== 
==12069== Stack overflow in thread #1: can't grow stack to 0x1ffe801000
==12069== 
==12069== Process terminating with default action of signal 11 (SIGSEGV)
==12069==  Access not within mapped region at address 0x1FFE801FF8
==12069== Stack overflow in thread #1: can't grow stack to 0x1ffe801000
==12069==    at 0x1091F3: silly_add (task6.c:8)
==12069==  If you believe this happened as a result of a stack
==12069==  overflow in your program's main thread (unlikely but
==12069==  possible), you can try to increase the size of the
==12069==  main thread stack using the --main-stacksize= flag.
==12069==  The main thread stack size used in this run was 8388608.
==12069== Stack overflow in thread #1: can't grow stack to 0x1ffe801000
==12069== 
==12069== Process terminating with default action of signal 11 (SIGSEGV)
==12069==  Access not within mapped region at address 0x1FFE801FF0
==12069== Stack overflow in thread #1: can't grow stack to 0x1ffe801000
==12069==    at 0x4831134: _vgnU_freeres (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_core-amd64-linux.so)
==12069==  If you believe this happened as a result of a stack
==12069==  overflow in your program's main thread (unlikely but
==12069==  possible), you can try to increase the size of the
==12069==  main thread stack using the --main-stacksize= flag.
==12069==  The main thread stack size used in this run was 8388608.
==12069== 
==12069== HEAP SUMMARY:
==12069==     in use at exit: 0 bytes in 0 blocks
==12069==   total heap usage: 0 allocs, 0 frees, 0 bytes allocated
==12069== 
==12069== All heap blocks were freed -- no leaks are possible
==12069== 
==12069== For lists of detected and suppressed errors, rerun with: -s
==12069== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
Segmentation fault (core dumped)

We can use ulimit to solve the problem temporarily. From checking ulimit -s we can see that stack-size is 8192 bytes. 

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ulimit
unlimited
owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ulimit -s
8192

Then the temporary fix is to set it to unlimited.

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ulimit -s unlimited

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 1 261869
261870
owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 1 261870
261871
owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 1 290000
290001
owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 1 500000
500001
owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 1 1000000
1000001
owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 1 10000000
10000001

(Did not wish to do any higher integers than that, because it got lengthy).



## PART 2 ##



### TASK 1 ###



1 processor with vmstat 1:

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 1
allocating 1048576 bytes (1.00 MB)
  number of integers in array: 262144
loop 0 in 1.06 ms (bandwidth: 945.09 MB/s)
loop 3991 in 0.48 ms (bandwidth: 2078.45 MB/s)
loop 8032 in 0.47 ms (bandwidth: 2136.68 MB/s)
loop 12008 in 0.47 ms (bandwidth: 2132.34 MB/s)
loop 15994 in 0.47 ms (bandwidth: 2141.04 MB/s)
loop 20040 in 0.47 ms (bandwidth: 2132.34 MB/s)

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 8
allocating 8388608 bytes (8.00 MB)
  number of integers in array: 2097152
loop 0 in 10.25 ms (bandwidth: 780.64 MB/s)
loop 501 in 3.82 ms (bandwidth: 2091.53 MB/s)
loop 995 in 3.79 ms (bandwidth: 2109.68 MB/s)
loop 1485 in 3.81 ms (bandwidth: 2099.25 MB/s)
loop 1983 in 3.81 ms (bandwidth: 2097.55 MB/s)
loop 2483 in 3.97 ms (bandwidth: 2015.16 MB/s)

vmstat's usertime column is the time spent running non-kernel code. 

When running vmstat 1 with 1 instance of mem, the usertime goes from 27 > 3 > 32 > 1 > 0 > 1 > 0 > 2 > 68 before then jumping to near 100 and staying there. 96 > 97 > 98 > 90 > 99 > 100 > 100 ... > 100.

When running vmstat 1 with 2 instances of mem, the usertime goes from 28 > 100 > 100 ... > 100. So it is apparent with multiple instances the usertime column shows the maximum number and it is not performing well. 

Now let's try 4 processors with vmstat 1:

When running vmstat 1 with 1 instance of mem, the usertime essentially stays stable at 25. Sometimes jumping slighly higher. The lowest it goes is 25 and the highest is 35.

When running vmstat 1 with 2 instances of mem, the usertime again essentially stays stable at 25. However, it is not fluctuating as much in the usertime column. It never really goes above 26.



### TASK 2 ###



I first run 1024 instances of mem (1024 MB) and then I run vmstat 1.

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 1024
allocating 1073741824 bytes (1024.00 MB)
  number of integers in array: 268435456
loop 0 in 2889.80 ms (bandwidth: 354.35 MB/s)
loop 5 in 490.37 ms (bandwidth: 2088.24 MB/s)
loop 9 in 494.56 ms (bandwidth: 2070.52 MB/s)
loop 13 in 542.59 ms (bandwidth: 1887.25 MB/s)
loop 17 in 494.34 ms (bandwidth: 2071.46 MB/s)
loop 21 in 527.67 ms (bandwidth: 1940.59 MB/s)

 3  0      0 >>>4978772<<<  47116 1254260    0    0     0     0 1633 3742 31  1 68  0  0
 0  0      0 >>>6028408<<<  47116 1254260    0    0     0   948 1752 3904 17  2 82  0

To see if it is the expected amount of free'd up memory we can just take 
6028408 - 4978772 = 1049636 which is 1049 MB, almost 1024 MB. Since the values are that close, we have achieved the expected result.



### TASK 3 ###



owe005@owe005-VirtualBox:~/Documents/inf113oblig$  free -h
              total        used        free      shared  buff/cache   available
Mem:          7,8Gi       813Mi       5,7Gi        25Mi       1,2Gi       6,7Gi
Swap:         773Mi          0B       773Mi

Total memory is 7,8 GB and free memory is 5,7GB. I will then pick 7 GB. 

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0 140784 116644   4952 140428    2   24   190    45  160  281  8  1 91  0  0
 1  0 140784 116392   4952 140584   16    0    16     0  428  283 25  0 75  0  0
 1  0 140784 116392   4952 140584    4    0     4     0  479  480 25  0 75  0  0
 1  1 140784 110344   4952 140392 6488    0  6488     0 3420 4628 25  1 70  4  0
 2  0 168792 118408   4916 140240 8004 28188  8004 28188 3793 4481 25  1 63 11  0
 1  0 168792 118408   4916 140240   24    0    24     0  425  351 25  0 75  0  0
 1  0 168792 118408   4916 140240   12    0    12     0  441  461 25  0 75  0  0
 1  0 168792 118408   4916 140240    0    0     0     0  421  300 25  0 75  0  0
 1  0 168792 118408   4916 140240    0    0     0     0  441  372 25  0 75  0  0
 1  0 168792 118156   4916 140240    0    0     0     0  460  443 25  0 75  0  0
 1  0 168792 118156   4916 140240    0    0     0     0  409  308 25  0 75  0  0
 1  0 168792 118156   4916 140240    0    0     0     0  427  354 25  1 75  0  0
 1  0 168792 118156   4916 140240    8    0     8     0  424  317 25  0 75  0  0

What I'm seeing is the memory swapped in from disk fluctuates a lot, and it is the same with memory swapped to disk. This is due to running out of memory. When memory is critically scarce, swapping begins to take place.



### TASK 4 ###



It drops by A LOT more than 50% when I run it with 7.5GB memory. 

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 7500
allocating 7864320000 bytes (7500.00 MB)
  number of integers in array: 1966080000
loop 0 in 9364.19 ms (bandwidth: 800.92 MB/s)
loop 1 in 137664.90 ms (bandwidth: 54.48 MB/s)

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 2  0 670860 118172   3340 108648 1047 1213  1197  1226  294  391  8  1 89  2  0
 2  1 667080 115904   3340 107644 50872 54056 50872 54056 10197 9585  1  6 72 21  0
 0  1 666400 115644   3340 107092 28624 30968 28624 30968 6043 9342  3  6 69 22  0
 0  1 672844 120936   3340 106272 26604 35056 26604 35056 3777 3721  1  3 72 24  0

The si and so columns show high numbers of memory swapping. Again showing that it's running out of memory or that the memory is critically low.



### TASK 5 ###



Running mem with 8GB of memory kills the program and with 10GB we get a memory allocation failed error as output. 

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 8000
allocating 8388608000 bytes (8000.00 MB)
  number of integers in array: 2097152000
Killed

owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 8733
allocating 9157214208 bytes (8733.00 MB)
memory allocation failed
owe005@owe005-VirtualBox:~/Documents/inf113oblig$ ./main 8732
allocating 9156165632 bytes (8732.00 MB)
  number of integers in array: 2289041408
  
As seen above, the program fails to allocate memory at 8733 MB of memory. 


